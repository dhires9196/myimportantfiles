{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dhire\\anaconda3\\envs\\tensorflowhub\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Wav2Vec2 is a speech model that accepts a float array corresponding to the raw waveform of the speech signal.\n",
    "##managing audio files as it needs to sample to 16000 HZ\n",
    "import librosa\n",
    "#it is from favebook ai\n",
    "import torch\n",
    "#Wav2Vec2 model was trained using connectionist temporal classification (CTC) \n",
    "#so the model output has to be decoded using Wav2Vec2CTCTokenizer.\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load any audio file of your choice\n",
    "speech, rate = librosa.load(\"testrecording_smartbot.wav\",sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
      "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#load pre-trained model and tokenizer\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "##convert the speech into tensor and it shoudl be in pytorch format\n",
    "input_values = tokenizer(speech, return_tensors = 'pt').input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0013,  0.0013,  0.0013,  ...,  0.0173, -0.0176,  0.0744]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store logits (non-normalized predictions)\n",
    "logits = model(input_values).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 15.0263, -24.5651, -24.2693,  ...,  -5.8067,  -5.9390,  -6.0746],\n",
       "         [ 14.9257, -24.2793, -23.9839,  ...,  -5.6584,  -5.6132,  -6.1034],\n",
       "         [ 15.0115, -24.5488, -24.2612,  ...,  -5.7415,  -5.8605,  -6.0855],\n",
       "         ...,\n",
       "         [ 15.2862, -24.7801, -24.4864,  ...,  -5.7889,  -6.1346,  -6.0460],\n",
       "         [ 14.9855, -24.4853, -24.1897,  ...,  -5.5765,  -6.0223,  -6.1416],\n",
       "         [ 14.7849, -24.3949, -24.1052,  ...,  -5.8031,  -6.1497,  -6.1665]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store predicted id's\n",
    "predicted_ids = torch.argmax(logits, dim =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 19,  8, 16, 15, 15, 14,  4,  4,\n",
       "         22,  8, 16, 16,  4, 23, 23, 15,  0,  5,  0,  7,  0, 12,  5,  5,  4,  4,\n",
       "         11,  0,  0,  5,  0, 15,  0, 23,  0,  0,  4,  4,  0,  0, 17,  0,  0,  5,\n",
       "          5,  0,  4,  4,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 18,\n",
       "          0,  0,  0, 10,  6,  0, 11,  4,  4,  6, 11,  0,  0,  5,  0,  0,  0,  0,\n",
       "          4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 12,  0,  0,  0, 23,  0,\n",
       "         15,  0,  0,  5,  0,  0,  9,  0,  0,  0,  0, 10,  0,  0, 12,  0,  0,  0,\n",
       "          7,  0,  9,  9,  0,  0,  0,  0,  8,  0,  0,  0, 20,  0,  0,  0,  4,  4,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 12,  0,  0,  0, 17,\n",
       "          0,  0, 10,  0,  0,  0, 15,  5,  5, 14,  4,  0, 24,  0,  0,  0,  8,  0,\n",
       "          0, 22,  0,  0,  0,  0,  4,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 11,\n",
       "         11,  0,  8, 18,  0,  4,  4,  0,  0, 10,  0,  6,  0,  4,  0, 11,  0,  5,\n",
       "          0,  0,  4, 21,  0,  8,  0,  0, 10, 10,  9,  0, 21,  4,  4,  0,  6,  8,\n",
       "          0,  4,  4, 11, 11,  0,  5, 15,  0,  0, 23,  0,  0,  4,  4,  4,  0,  0,\n",
       "         16,  0, 12, 12,  4,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 19,  8, 16, 15, 15, 14,  4,  4,\n",
       "        22,  8, 16, 16,  4, 23, 23, 15,  0,  5,  0,  7,  0, 12,  5,  5,  4,  4,\n",
       "        11,  0,  0,  5,  0, 15,  0, 23,  0,  0,  4,  4,  0,  0, 17,  0,  0,  5,\n",
       "         5,  0,  4,  4,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 18,\n",
       "         0,  0,  0, 10,  6,  0, 11,  4,  4,  6, 11,  0,  0,  5,  0,  0,  0,  0,\n",
       "         4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 12,  0,  0,  0, 23,  0,\n",
       "        15,  0,  0,  5,  0,  0,  9,  0,  0,  0,  0, 10,  0,  0, 12,  0,  0,  0,\n",
       "         7,  0,  9,  9,  0,  0,  0,  0,  8,  0,  0,  0, 20,  0,  0,  0,  4,  4,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 12,  0,  0,  0, 17,\n",
       "         0,  0, 10,  0,  0,  0, 15,  5,  5, 14,  4,  0, 24,  0,  0,  0,  8,  0,\n",
       "         0, 22,  0,  0,  0,  0,  4,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 11,\n",
       "        11,  0,  8, 18,  0,  4,  4,  0,  0, 10,  0,  6,  0,  4,  0, 11,  0,  5,\n",
       "         0,  0,  4, 21,  0,  8,  0,  0, 10, 10,  9,  0, 21,  4,  4,  0,  6,  8,\n",
       "         0,  4,  4, 11, 11,  0,  5, 15,  0,  0, 23,  0,  0,  4,  4,  4,  0,  0,\n",
       "        16,  0, 12, 12,  4,  4,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decode the audio to generate text\n",
    "transcriptions = tokenizer.decode(predicted_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COULD YOU PLEASE HELP ME WITH THE SPLENISANOF SMILED BOY HOW IT HE GOING TO HELP US'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "697c8ed5ccc42803ca9995f225476357344f1231a0856324e44118eb17a0e86f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflowhub')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
